\section{Related Work}

% Framing paragraph
Chapter 2 situates this study within the broader literature on textual analysis in finance. Prior research has established that issuer-authored narrative disclosures contain economically meaningful information beyond numerical accounting data \citep{tetlock2008morethanwords}. A substantial body of work has focused specifically on extracting sentiment from financial texts, with early evidence showing that domain-specific sentiment dictionaries are effective for analyzing English-language disclosures \citep{loughran2011liability}. However, extending these dictionary-based methods to non-English settings introduces additional linguistic and methodological challenges. This chapter reviews evidence documenting the limitations of cross-language dictionary transfer and motivates the methodological choices adopted in this study. For a broader overview of textual sentiment methods and applications in finance, see \citet{kearney2014textualsentiment}.

% Broad use of NLP in finance
A broader strand of the finance literature demonstrates that corporate narratives encode rich economic structure that can be systematically recovered using textual methods. For example, \citet{hoberg2016text} use text-based analysis of firms’ 10-K product descriptions to construct time-varying measures of product market similarity and show that these text-derived measures outperform traditional industry classifications in explaining competition, profitability, and firm behavior. In the specific context of periodic filings, large-sample evidence shows that year-over-year changes in MD\&A language are informative about underlying economic change \citep{brown2011mda}. Together, these studies motivate subsequent research that seeks to extract specific informational dimensions—such as sentiment—from financial texts.

% Cross-linguistic evidence (German, Chinese, Korean) showing that naive translation
% of English financial sentiment dictionaries does not generalize across languages.
While \citet{loughran2011liability} provide the dominant dictionary-based framework for sentiment analysis in English-language financial disclosures, a growing literature demonstrates that this methodology does not generalize mechanically to non-English settings. Evidence from German corporate reports shows that naive word-by-word translation of the Loughran–McDonald dictionary introduces systematic measurement error due to linguistic features such as inflection and compounding, requiring substantial language-specific adaptation \citep{bannier2018german}. Similarly, studies using Chinese financial texts find that translated Loughran–McDonald dictionaries are subsumed and dominated by sentiment lexicons reconstructed directly from native-language corpora \citep{du2022chinese}. Consistent with these findings, recent work in Korean financial analysis demonstrates that both general-purpose Korean sentiment lexicons and translated English finance dictionaries perform poorly relative to a newly constructed, finance-specific Korean lexicon, even when validated against analyst recommendations and target price changes \citep{kim2021korean}. Collectively, this cross-linguistic evidence suggests that dictionary-based sentiment measures are highly language- and domain-dependent, motivating alternative approaches for analyzing non-English financial disclosures.

% BERT
\subsection{Transformer-based encoders: BERT and domain adaptation}
Transformer architectures enabled large gains in text classification by pretraining on large corpora and fine-tuning on downstream tasks. \citet{devlin2019bert} introduce BERT, a bidirectional Transformer encoder trained with masked language modeling, which can be fine-tuned efficiently for classification problems such as sentiment prediction. In finance, domain-adapted BERT variants (FinBERT) further improve performance by continuing pretraining on financial corpora and then fine-tuning for sentiment and related tasks \citep{yang2020finbert}. These models provide a natural baseline for supervised sentiment extraction in financial disclosures, including non-English settings when suitable pretrained models or domain corpora are available.

% GPT
\subsection{Autoregressive large language models: GPT and instruction tuning}
In parallel, autoregressive Transformer models pretrained to predict the next token (the GPT family) have enabled strong zero-shot and few-shot performance across many NLP tasks \citep{radford2018improving}. Modern chat-oriented systems additionally apply instruction tuning and reinforcement learning from human feedback (RLHF) to improve helpfulness and adherence to user intent \citep{ouyang2022instructgpt}. GPT-4 extends this paradigm with substantially increased capability and broader benchmark performance \citep{openai2023gpt4}. In financial applications, these models can be used directly for document-level sentiment inference via prompting, but their post-training alignment may also shape outputs (e.g., systematic positivity), motivating careful evaluation and robustness checks.

% This subsection motivates moving beyond dictionary-based sentiment for Japanese MD&A
Building on these modeling advances, recent studies applying transformer-based and large language models to Japanese financial texts, including the Japanese Company Handbook, further underscore the limitations of dictionary-based sentiment measures in this context. For example, \citet{Suzuki2025Sentiment} analyze sentiment extracted from the Japanese Company Handbook using financial sentiment dictionaries, fine-tuned transformer models, and large language models such as ChatGPT and GPT-4. They find that context-aware models consistently outperform dictionary-based approaches in predicting excess stock returns, with particularly strong effects among small-cap stocks, while also documenting practical challenges associated with large language models, including discretized sentiment outputs and alignment-induced positivity bias. Relatedly, \citet{okada2025words} apply large language models directly to Japanese corporate disclosures and show that sentiment derived from GPT-4, Claude, and Gemini predicts future stock returns, whereas dictionary-based measures exhibit no significant predictive power. Together, these findings suggest that advanced language models can extract economically meaningful signals from Japanese narrative texts that are not captured by traditional dictionary methods. However, existing studies primarily emphasize return predictability and portfolio performance, leaving open questions regarding how alternative sentiment extraction methods compare under controlled experimental conditions and how such sentiment relates to analyst behavior and forecasting outcomes.

% Language effects on information incorporation
Prior research also documents that written language itself affects how textual information is incorporated into prices. For example, \citet{miwa2021language} show that while stock prices react to negative linguistic tone in both Japanese and U.S. analyst reports, investors underreact to Japanese-language reports, and this underreaction is mitigated when an English translation is provided.

% Gap statement
Accordingly, there remains limited empirical evidence comparing traditional and transformer-based sentiment analysis methods under consistent experimental conditions in Japanese financial disclosures. The next section introduces the data and empirical framework used to evaluate these methods in the context of Japanese MD\&A texts.

